{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/balajivijayakumar1994/mlnotebook/blob/main/Second_Iris_Data_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# 1. Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data  # Features: Sepal and Petal measurements\n",
        "y = iris.target  # Labels: 0, 1, or 2 (Setosa, Versicolor, Virginica)\n",
        "\n",
        "# 2. Preprocess the data\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features (important for neural networks)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# 3. Build a neural network\n",
        "model = Sequential([\n",
        "    Dense(10, input_dim=4, activation='relu'),  # Input layer + hidden layer (10 neurons)\n",
        "    Dense(3, activation='softmax')  # Output layer (3 neurons for 3 classes)\n",
        "])\n",
        "\n",
        "# 4. Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 5. Train the model\n",
        "model.fit(X_train, y_train, epochs=50, batch_size=5, verbose=1)\n",
        "\n",
        "# 6. Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "id": "Zs2XpAeOceXO",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55d4e9ff-d02d-428a-ac97-d30c5ddda0ff"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.2356 - loss: 1.1606\n",
            "Epoch 2/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.3217 - loss: 1.0345\n",
            "Epoch 3/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3054 - loss: 1.0339\n",
            "Epoch 4/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4561 - loss: 0.8963\n",
            "Epoch 5/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4062 - loss: 0.9084\n",
            "Epoch 6/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4256 - loss: 0.8925\n",
            "Epoch 7/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4875 - loss: 0.7907\n",
            "Epoch 8/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5084 - loss: 0.7376\n",
            "Epoch 9/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4679 - loss: 0.7647\n",
            "Epoch 10/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5444 - loss: 0.7087\n",
            "Epoch 11/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8029 - loss: 0.6513  \n",
            "Epoch 12/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7928 - loss: 0.7170 \n",
            "Epoch 13/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7853 - loss: 0.7099 \n",
            "Epoch 14/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8492 - loss: 0.5841 \n",
            "Epoch 15/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8643 - loss: 0.5387 \n",
            "Epoch 16/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8382 - loss: 0.5629 \n",
            "Epoch 17/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7974 - loss: 0.5554 \n",
            "Epoch 18/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8339 - loss: 0.5411 \n",
            "Epoch 19/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8485 - loss: 0.4687 \n",
            "Epoch 20/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8717 - loss: 0.4367 \n",
            "Epoch 21/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8893 - loss: 0.4261 \n",
            "Epoch 22/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8559 - loss: 0.4159 \n",
            "Epoch 23/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9224 - loss: 0.3709 \n",
            "Epoch 24/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9228 - loss: 0.3544 \n",
            "Epoch 25/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9245 - loss: 0.3591 \n",
            "Epoch 26/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8884 - loss: 0.3679 \n",
            "Epoch 27/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8530 - loss: 0.3747 \n",
            "Epoch 28/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9301 - loss: 0.3002 \n",
            "Epoch 29/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8966 - loss: 0.3358 \n",
            "Epoch 30/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9159 - loss: 0.3076 \n",
            "Epoch 31/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9194 - loss: 0.3055 \n",
            "Epoch 32/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8983 - loss: 0.3083 \n",
            "Epoch 33/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9687 - loss: 0.2161 \n",
            "Epoch 34/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9466 - loss: 0.2855 \n",
            "Epoch 35/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9518 - loss: 0.2352 \n",
            "Epoch 36/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9584 - loss: 0.2207 \n",
            "Epoch 37/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9423 - loss: 0.2650 \n",
            "Epoch 38/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9610 - loss: 0.2281 \n",
            "Epoch 39/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9856 - loss: 0.2174 \n",
            "Epoch 40/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9742 - loss: 0.2200 \n",
            "Epoch 41/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9794 - loss: 0.2124 \n",
            "Epoch 42/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9577 - loss: 0.2082 \n",
            "Epoch 43/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9497 - loss: 0.2276 \n",
            "Epoch 44/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9747 - loss: 0.1855 \n",
            "Epoch 45/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9639 - loss: 0.2155 \n",
            "Epoch 46/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9833 - loss: 0.1642 \n",
            "Epoch 47/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9654 - loss: 0.1965 \n",
            "Epoch 48/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9315 - loss: 0.2174 \n",
            "Epoch 49/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9147 - loss: 0.2270 \n",
            "Epoch 50/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9718 - loss: 0.1649 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 1.0000 - loss: 0.1369\n",
            "Test accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# New data point: [sepal length, sepal width, petal length, petal width]\n",
        "new_data = np.array([[9.1, 9.5, 1.4, 9.2]])  # Example: Setosa\n",
        "\n",
        "# Standardize the new data (just like we did for training data)\n",
        "new_data = scaler.transform(new_data)\n",
        "\n",
        "# Make a prediction\n",
        "prediction = model.predict(new_data)\n",
        "predicted_class = np.argmax(prediction)  # Get the class with the highest probability\n",
        "\n",
        "# Print the predicted class\n",
        "print(f\"Predicted class: {predicted_class}\")\n",
        "\n",
        "# Print probabilities for each class\n",
        "print(f\"Prediction probabilities: {prediction}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYIlnJ6UeLbr",
        "outputId": "a3b1757a-ea0e-47b9-99e7-016f7a94a3f2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
            "Predicted class: 2\n",
            "Prediction probabilities: [[4.1308303e-06 6.6439370e-08 9.9999583e-01]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Load and preprocess the dataset\n",
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "\n",
        "# Normalize images\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "# Reshape to add channel (grayscale = 1 channel)\n",
        "train_images = train_images.reshape(-1, 28, 28, 1)\n",
        "test_images = test_images.reshape(-1, 28, 28, 1)\n",
        "\n",
        "# Class names for display\n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "\n",
        "# Build CNN model\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(train_images, train_labels, epochs=5, validation_split=0.1)\n",
        "\n",
        "# Evaluate model\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(\"Test accuracy:\", test_acc)\n",
        "\n",
        "# Predict on test images\n",
        "predictions = model.predict(test_images)\n",
        "\n",
        "# View one of the test images\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFFh23CzDc1S",
        "outputId": "b3b1a06e-7071-4d0d-cc0c-f88aec78f3e1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 31ms/step - accuracy: 0.7685 - loss: 0.6541 - val_accuracy: 0.8655 - val_loss: 0.3748\n",
            "Epoch 2/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 31ms/step - accuracy: 0.8719 - loss: 0.3501 - val_accuracy: 0.8902 - val_loss: 0.2978\n",
            "Epoch 3/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 30ms/step - accuracy: 0.8950 - loss: 0.2840 - val_accuracy: 0.8950 - val_loss: 0.2809\n",
            "Epoch 4/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 30ms/step - accuracy: 0.9078 - loss: 0.2512 - val_accuracy: 0.8935 - val_loss: 0.2938\n",
            "Epoch 5/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 29ms/step - accuracy: 0.9175 - loss: 0.2251 - val_accuracy: 0.9040 - val_loss: 0.2690\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8968 - loss: 0.2901\n",
            "Test accuracy: 0.8996000289916992\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# View one of the test images with predicted and actual label\n",
        "def show_image_with_prediction(index):\n",
        "    plt.imshow(test_images[index].reshape(28, 28), cmap='gray')\n",
        "    plt.title(f\"Predicted: {class_names[np.argmax(predictions[index])]} | Actual: {class_names[test_labels[index]]}\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# View image at index 0\n",
        "show_image_with_prediction(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "gSbje00vFzLx",
        "outputId": "9e239d31-95a5-4ba8-cb1d-4a0f46eae907"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Overview of Colaboratory Features",
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}